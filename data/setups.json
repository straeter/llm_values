{
  "A) default (rating first, temperature=0, gpt-4o)": {
    "model": "gpt-4o-2024-05-13",
    "rating_last": false,
    "answer_english": false,
    "question_english": false,
    "temperature": 0.0,
    "topics": [
      "controversial_statements",
      "scientific_controversies",
      "un_global_issues"
    ]
  },
  "B) gpt-3.5-turbo": {
    "model": "gpt-3.5-turbo-0125",
    "rating_last": false,
    "answer_english": false,
    "question_english": false,
    "temperature": 0.0,
    "topics": [
      "controversial_statements"
    ]
  },
  "C) mistral-large": {
    "model": "mistral-large-2402",
    "rating_last": false,
    "answer_english": false,
    "question_english": false,
    "temperature": 0.0,
    "topics": [
      "controversial_statements"
    ]
  },
  "D) claude-3-opus": {
    "model": "claude-3-opus-20240229",
    "rating_last": false,
    "answer_english": false,
    "question_english": false,
    "temperature": 0.0,
    "topics": [
      "controversial_statements"
    ]
  },
  "E) temperature=1.0": {
    "model": "gpt-4o-2024-05-13",
    "rating_last": false,
    "answer_english": false,
    "question_english": false,
    "temperature": 1.0,
    "topics": [
      "controversial_statements"
    ]
  },
  "F) rating last": {
    "model": "gpt-4o-2024-05-13",
    "rating_last": true,
    "answer_english": false,
    "question_english": false,
    "temperature": 0.0,
    "topics": [
      "controversial_statements"
    ]
  },
  "G) Question in English": {
    "model": "gpt-4o-2024-05-13",
    "rating_last": true,
    "answer_english": false,
    "question_english": true,
    "temperature": 0.0,
    "topics": [
      "controversial_statements"
    ]
  },
  "H) Answer in English": {
    "model": "gpt-4o-2024-05-13",
    "rating_last": true,
    "answer_english": true,
    "question_english": false,
    "temperature": 0.0,
    "topics": [
      "controversial_statements"
    ]
  }
}